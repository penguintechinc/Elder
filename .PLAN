# Elder v1.2.0: Complete Integration & Entity Enhancement

**Date:** 2025-10-27
**Status:** IN PROGRESS - Foundation Commit Ready
**Target Release:** v1.2.0
**Timeline:** 18 weeks

---

## ðŸŽ¯ Implementation Progress

### âœ… Phase 1: COMPLETED
- Entity sub-types model created (apps/api/models/entity_types.py)
- Entity table updated with sub_type and default_metadata fields
- Entity types API endpoints implemented (6 endpoints)
- Blueprint registered in main.py

### âœ… Database Foundation: COMPLETED
- All Phase 2-11 database schemas added to pydal_models.py:
  - Phase 2: secret_providers, secrets, secret_access_log
  - Phase 3: key_providers, keys, key_access_log
  - Phase 5: discovery_jobs, cloud_accounts, discovery_history
  - Phase 8: audit_retention_policies
  - Phase 9: webhooks, webhook_deliveries, notification_rules
  - Phase 10: saved_searches, backup_jobs

### âœ… API Foundation: COMPLETED
- Stub API files created for all key phases:
  - apps/api/api/v1/secrets.py (Phase 2: 17 endpoints)
  - apps/api/api/v1/keys.py (Phase 3: 17 endpoints)
  - apps/api/api/v1/discovery.py (Phase 5: 14 endpoints)
  - apps/api/api/v1/webhooks.py (Phase 9: 14 endpoints)
  - apps/api/api/v1/search.py (Phase 10: 14 endpoints)
  - apps/api/api/v1/backup.py (Phase 10: 19 endpoints)
- All blueprints registered in main.py

### ðŸ“‹ Ready for Implementation
- Database schemas ready for migration
- API structure in place
- Entity type system fully functional
- Ready to implement Phase 2-11 functionality

## Overview

Complete implementation of ALL features from .FUTURE plus comprehensive infrastructure visibility:
- Entity sub-types (network, compute, storage, datacenter, security)
- Secrets management (AWS Secrets Manager, GCP Secrets, Infisical)
- Keys management (AWS KMS, GCP KMS, Infisical)
- IAM integration (AWS IAM, GCP IAM, Kubernetes RBAC)
- Cloud auto-discovery (AWS, GCP, Azure)
- Directory integration (LDAP/AD, Google Workspace, Azure AD)
- Database enhancement (MariaDB Galera, read replicas)
- Audit system enhancement
- Webhook & notification system
- Advanced search & data management

---

## Component Distribution

**ðŸ”µ CORE CONTAINER (apps/api + web):**
- Database models and migrations
- REST API endpoints
- Frontend UI components
- Authentication/authorization
- All CRUD operations

**ðŸŸ¢ CONNECTOR CONTAINER (apps/connector):**
- Cloud provider discovery (AWS, GCP, Azure)
- Directory sync (LDAP, Google Workspace, Azure AD)
- IAM integration (AWS IAM, GCP IAM, K8s)
- Secrets fetching (AWS Secrets Manager, GCP Secrets, Infisical)
- Keys fetching (AWS KMS, GCP KMS, Infisical)
- Scheduled sync jobs

---

## Phase 1: Entity Sub-Types & Model Enhancement (Weeks 1-3)

### ðŸ”µ CORE CONTAINER

**Files Modified:**
- `apps/api/models/entity.py` - Add entity sub-types enum
- `apps/api/models/pydal_models.py` - Update entity table with sub_type field
- `apps/api/migrations/002_entity_subtypes.py` - Migration for entity sub-types

**Entity Type Reorganization (from .FUTURE):**

#### Network Sub-Types
- `subnet` - Merged from top-level to sub-entity
- `firewall` - Firewall/security group
- `proxy` - Load balancer/reverse proxy
- `router` - Network router
- `switch` - Network switch
- `hub` - Network hub
- `tunnel` - VPN/tunnel
- `route_table` - Routing table
- `vrrf` - Virtual routing and forwarding
- `vxlan` - VXLAN network
- `vlan` - VLAN network
- `other` - Other network device

#### Compute Sub-Types
- `server` - Physical server
- `serverless` - Serverless function/lambda
- `laptop` - Laptop device
- `mobile` - Mobile device
- `desktop` - Desktop computer
- `kubernetes_node` - Kubernetes worker node
- `virtual_machine` - Virtual machine
- `kubernetes_cluster` - Kubernetes cluster
- `function_run` - Function execution
- `other` - Other compute resource

#### Storage Sub-Types
- `hard_disk` - Hard disk drive
- `nvme_disk` - NVMe disk
- `solid_state_disk` - SSD
- `virtual_disk` - Virtual disk
- `external_drive` - External storage
- `database` - Database instance
- `caching` - Redis/Valkey cache
- `queue_system` - SQS/Kafka queue
- `other` - Other storage

#### Datacenter Sub-Types
- `public_vpc` - Public VPC/VNet
- `private_vpc` - Private VPC/VNet
- `physical` - Physical datacenter
- `closet` - Network closet
- `other` - Other datacenter

#### Security Sub-Types
- `vulnerability` - Security vulnerability
- `architectural` - Architectural issue
- `config` - Configuration issue
- `compliance` - Compliance violation
- `code` - Code security issue
- `regulatory` - Regulatory concern
- `other` - Other security issue

#### User â†’ Identity Migration
- Remove `user` entity type entirely
- Migrate all user entities to identities table
- Update all foreign keys and relationships

**Default Metadata by Sub-Type:**

Router metadata:
- `routing_protocols`: array of protocols (BGP, OSPF, etc.)
- `routing_table`: routing table data

Database metadata:
- `engine`: PostgreSQL, MySQL, etc.
- `version`: Database version
- `port`: Database port

Server metadata:
- `os`: Operating system
- `kernel_version`: Kernel version
- `cpu_count`: Number of CPUs
- `memory_gb`: Memory in GB

(Full mapping for all sub-types in code)

**Database Changes:**

```python
# apps/api/models/pydal_models.py
db.define_table(
    "entities",
    Field("name", "string", length=255, notnull=True),
    Field("type", "string", length=50, notnull=True),  # network, compute, storage, datacenter, security
    Field("sub_type", "string", length=50),  # firewall, router, server, etc.
    Field("default_metadata", "json"),  # Default metadata for sub-type
    # ... existing fields
)
```

**API Endpoints:**

- `GET /api/v1/entities?type=network&sub_type=router` - Filter by type and sub-type
- `POST /api/v1/entities` - Create entity with sub_type
- `PATCH /api/v1/entities/{id}` - Update entity sub_type
- `GET /api/v1/entity-types` - List all types and sub-types
- `GET /api/v1/entity-types/{type}/sub-types` - Get sub-types for a type
- `GET /api/v1/entity-types/{type}/metadata` - Get default metadata schema for type
- `GET /api/v1/entity-types/{type}/{sub_type}/metadata` - Get default metadata for sub-type

**UI Components:**

- `web/src/components/EntityTypeSelector.tsx` - Cascading type/sub-type dropdown
- `web/src/components/EntityForm.tsx` - Update to support sub-types and default metadata
- `web/src/components/EntityList.tsx` - Add sub-type filter
- `web/src/pages/EntityTypes.tsx` - Browse entity types and sub-types

**Migration Script:**

```python
# apps/api/migrations/002_entity_subtypes.py
def migrate_users_to_identities():
    """Migrate user entities to identities table"""
    # Find all entities with type='user'
    # Create corresponding identities
    # Update all foreign keys
    # Delete user entities
    pass
```

---

## Phase 2: Secrets Management System (Weeks 3-6)

### ðŸ”µ CORE CONTAINER

**Database Schema:**

**New File: `apps/api/models/secret.py`**

```python
class SecretType(enum.Enum):
    """Secret hierarchy types"""
    PATH = "path"  # Path container (e.g., /alpha/application/)
    CONTAINER = "container"  # Secret container object
    SECRET = "secret"  # Actual secret (string or KV)

class SecretProvider(enum.Enum):
    """Supported secret providers"""
    AWS_SECRETS_MANAGER = "aws_secrets_manager"
    GCP_SECRETS = "gcp_secrets"
    INFISICAL = "infisical"
```

**PyDAL Table:**

```python
# apps/api/models/pydal_models.py
db.define_table(
    "secret_providers",
    Field("name", "string", length=255, notnull=True, unique=True),
    Field("provider", "string", length=50, notnull=True),  # aws_secrets_manager, gcp_secrets, infisical
    Field("config_json", "json", notnull=True),  # Provider-specific config
    Field("organization_id", "reference organizations"),  # Optional: scope to OU
    Field("enabled", "boolean", default=True),
    Field("last_sync_at", "datetime"),
    Field("created_at", "datetime", default=datetime.utcnow),
)

db.define_table(
    "secrets",
    Field("name", "string", length=255, notnull=True),
    Field("provider_id", "reference secret_providers", notnull=True),
    Field("provider_path", "string", length=500, notnull=True),  # Path in provider
    Field("secret_type", "string", length=20, notnull=True),  # path, container, secret
    Field("is_kv", "boolean", default=False),  # String vs KV pair
    Field("organization_id", "reference organizations", notnull=True),  # For access control
    Field("parent_id", "reference secrets"),  # For hierarchy (path -> container -> secret)
    Field("metadata", "json"),  # Creation time, rotation policy from provider
    Field("last_synced_at", "datetime"),
    Field("created_at", "datetime", default=datetime.utcnow),
)

db.define_table(
    "secret_access_log",
    Field("secret_id", "reference secrets", notnull=True),
    Field("identity_id", "reference identities", notnull=True),
    Field("action", "string", length=20, notnull=True),  # view, unmask
    Field("masked", "boolean", default=True),
    Field("accessed_at", "datetime", default=datetime.utcnow),
)
```

**API Endpoints:**

**New File: `apps/api/api/v1/secrets.py`**

- `POST /api/v1/secret-providers` - Configure provider with wizard
- `GET /api/v1/secret-providers` - List configured providers
- `GET /api/v1/secret-providers/{id}` - Get provider details
- `PATCH /api/v1/secret-providers/{id}` - Update provider config
- `DELETE /api/v1/secret-providers/{id}` - Delete provider
- `GET /api/v1/secret-providers/{id}/onboarding` - Get CLI commands for setup

- `GET /api/v1/secrets` - List secrets (masked by default, filtered by OU permissions)
- `GET /api/v1/secrets/{id}` - Get secret details (masked)
- `GET /api/v1/secrets/{id}/unmask` - Unmask secret (requires permission, logged)
- `POST /api/v1/secrets/sync` - Trigger sync from all providers
- `POST /api/v1/secrets/sync/{provider_id}` - Sync specific provider
- `GET /api/v1/secrets/{id}/access-log` - Get access history for secret

**Permission Checks:**

```python
@token_required
@resource_role_required(ResourceType.SECRET, ResourceRoleType.VIEWER)
def get_secret(current_user, secret_id):
    """Get secret details (masked)"""
    # Check OU-based access
    # Return masked secret
    pass

@token_required
@resource_role_required(ResourceType.SECRET, ResourceRoleType.MAINTAINER)
def unmask_secret(current_user, secret_id):
    """Unmask secret value (requires elevated permission)"""
    # Check OU-based access
    # Log access to secret_access_log
    # Fetch from provider dynamically (never stored)
    # Return unmasked value
    pass
```

**UI Components:**

**New Files:**

1. `web/src/pages/SecretProviders.tsx` - List/manage secret providers
2. `web/src/components/SecretProviderWizard.tsx` - Onboarding wizard with CLI commands
   - AWS Secrets Manager: Show IAM policy + CLI commands to create service account
   - GCP Secrets: Show gcloud commands for service account
   - Infisical: Show API token generation
3. `web/src/pages/Secrets.tsx` - List secrets with mask/unmask capability
4. `web/src/components/SecretDetail.tsx` - Secret details with metadata
5. `web/src/components/SecretAccessControl.tsx` - Manage OU-based permissions
6. `web/src/components/SecretAccessLog.tsx` - View who accessed secret

**Onboarding Wizard Content:**

AWS Secrets Manager:
```bash
# Create IAM user for Elder
aws iam create-user --user-name elder-secrets-reader

# Create IAM policy
cat > elder-secrets-policy.json <<EOF
{
  "Version": "2012-10-17",
  "Statement": [{
    "Effect": "Allow",
    "Action": ["secretsmanager:GetSecretValue", "secretsmanager:ListSecrets"],
    "Resource": "*"
  }]
}
EOF
aws iam create-policy --policy-name ElderSecretsRead --policy-document file://elder-secrets-policy.json

# Attach policy to user
aws iam attach-user-policy --user-name elder-secrets-reader --policy-arn arn:aws:iam::ACCOUNT:policy/ElderSecretsRead

# Create access key
aws iam create-access-key --user-name elder-secrets-reader
```

### ðŸŸ¢ CONNECTOR CONTAINER

**New Files:**

**`apps/connector/connectors/aws_secrets_connector.py`**

```python
class AWSSecretsConnector(BaseConnector):
    """Connector for AWS Secrets Manager"""

    def __init__(self, provider_config):
        super().__init__("aws_secrets")
        self.client = boto3.client(
            'secretsmanager',
            aws_access_key_id=provider_config['access_key'],
            aws_secret_access_key=provider_config['secret_key'],
            region_name=provider_config.get('region', 'us-east-1')
        )

    async def sync_secrets(self):
        """Discover and sync secrets from AWS"""
        # List all secrets
        # For each secret:
        #   - Fetch metadata (CreatedDate, LastChangedDate, etc.)
        #   - Create/update in Elder (never store value)
        #   - Build hierarchy (path -> container -> secret)
        pass

    async def get_secret_value(self, secret_name):
        """Dynamically fetch secret value (never cached)"""
        response = self.client.get_secret_value(SecretId=secret_name)
        return response['SecretString']
```

**`apps/connector/connectors/gcp_secrets_connector.py`**

```python
class GCPSecretsConnector(BaseConnector):
    """Connector for GCP Secret Manager"""

    def __init__(self, provider_config):
        super().__init__("gcp_secrets")
        from google.cloud import secretmanager
        self.client = secretmanager.SecretManagerServiceClient()
        self.project_id = provider_config['project_id']

    async def sync_secrets(self):
        """Discover and sync secrets from GCP"""
        pass

    async def get_secret_value(self, secret_name):
        """Dynamically fetch secret value"""
        name = f"projects/{self.project_id}/secrets/{secret_name}/versions/latest"
        response = self.client.access_secret_version(request={"name": name})
        return response.payload.data.decode('UTF-8')
```

**`apps/connector/connectors/infisical_connector.py`**

```python
class InfisicalConnector(BaseConnector):
    """Connector for Infisical secrets"""

    def __init__(self, provider_config):
        super().__init__("infisical")
        self.api_url = provider_config.get('url', 'https://app.infisical.com')
        self.api_key = provider_config['api_key']

    async def sync_secrets(self):
        """Discover and sync secrets from Infisical"""
        pass

    async def get_secret_value(self, secret_path):
        """Dynamically fetch secret value"""
        # Use Infisical API to fetch secret
        pass
```

**Scheduler Integration:**

```python
# apps/connector/scheduler.py
def schedule_secrets_sync():
    """Schedule periodic secrets metadata sync"""
    interval = int(os.getenv('SECRETS_SYNC_INTERVAL', 3600))
    scheduler.add_job(
        sync_all_secrets_metadata,
        'interval',
        seconds=interval,
        id='secrets_sync'
    )
```

---

## Phase 3: Key Management System (Weeks 6-8)

### ðŸ”µ CORE CONTAINER

**Database Schema:**

**New File: `apps/api/models/key.py`**

```python
class KeyProvider(enum.Enum):
    """Supported key providers"""
    AWS_KMS = "aws_kms"
    GCP_KMS = "gcp_kms"
    INFISICAL = "infisical"
```

**PyDAL Tables:**

```python
# apps/api/models/pydal_models.py
db.define_table(
    "key_providers",
    Field("name", "string", length=255, notnull=True, unique=True),
    Field("provider", "string", length=50, notnull=True),
    Field("config_json", "json", notnull=True),
    Field("organization_id", "reference organizations"),
    Field("enabled", "boolean", default=True),
    Field("last_sync_at", "datetime"),
    Field("created_at", "datetime", default=datetime.utcnow),
)

db.define_table(
    "keys",
    Field("name", "string", length=255, notnull=True),
    Field("provider_id", "reference key_providers", notnull=True),
    Field("provider_key_id", "string", length=500, notnull=True),  # Key ID in provider
    Field("key_hash", "string", length=255),  # Hash of public key (NEVER show private)
    Field("organization_id", "reference organizations", notnull=True),
    Field("metadata", "json"),  # Creation time, rotation schedule from provider
    Field("last_synced_at", "datetime"),
    Field("created_at", "datetime", default=datetime.utcnow),
)

db.define_table(
    "key_access_log",
    Field("key_id", "reference keys", notnull=True),
    Field("identity_id", "reference identities", notnull=True),
    Field("action", "string", length=20, notnull=True),  # view, use
    Field("accessed_at", "datetime", default=datetime.utcnow),
)
```

**API Endpoints:**

**New File: `apps/api/api/v1/keys.py`**

- `POST /api/v1/key-providers` - Configure key provider
- `GET /api/v1/key-providers` - List key providers
- `GET /api/v1/key-providers/{id}/onboarding` - Get setup CLI commands

- `GET /api/v1/keys` - List keys (show hash only)
- `GET /api/v1/keys/{id}` - Get key details (no private key)
- `POST /api/v1/keys/sync` - Sync keys from providers
- `GET /api/v1/keys/{id}/access-log` - Key access history

**UI Components:**

1. `web/src/pages/KeyProviders.tsx` - Manage key providers
2. `web/src/components/KeyProviderWizard.tsx` - Onboarding with CLI
3. `web/src/pages/Keys.tsx` - List keys
4. `web/src/components/KeyDetail.tsx` - Key details (no private key shown)

### ðŸŸ¢ CONNECTOR CONTAINER

**New Files:**

**`apps/connector/connectors/aws_kms_connector.py`**

```python
class AWSKMSConnector(BaseConnector):
    """Connector for AWS Key Management Service"""

    async def sync_keys(self):
        """Sync KMS keys metadata"""
        # List KMS keys
        # For each key:
        #   - Get key metadata
        #   - Get public key hash
        #   - Never expose private key
        pass
```

**`apps/connector/connectors/gcp_kms_connector.py`**

```python
class GCPKMSConnector(BaseConnector):
    """Connector for GCP Cloud KMS"""

    async def sync_keys(self):
        """Sync Cloud KMS keys metadata"""
        pass
```

**`apps/connector/connectors/infisical_keys_connector.py`**

```python
class InfisicalKeysConnector(BaseConnector):
    """Connector for Infisical keys"""

    async def sync_keys(self):
        """Sync Infisical keys metadata"""
        pass
```

---

## Phase 4: IAM Integration (Weeks 8-10)

### ðŸŸ¢ CONNECTOR CONTAINER

**New Files:**

**`apps/connector/connectors/aws_iam_connector.py`**

```python
class AWSIAMConnector(BaseConnector):
    """Connector for AWS IAM"""

    async def sync_iam(self):
        """Sync AWS IAM resources to Elder"""
        # IAM Users â†’ Elder Identities (type=user)
        # IAM Roles â†’ Elder Identity Groups (type=role)
        # IAM Groups â†’ Elder Identity Groups (type=group)
        # IAM Policies â†’ Metadata on identities/groups

        # Discovery includes:
        # - Users with access keys, MFA status
        # - Roles with trust policies
        # - Groups with attached policies
        # - Permission boundary analysis
        # - Cross-account roles
        pass

    async def discover_users(self):
        """Discover IAM users"""
        iam = boto3.client('iam')
        users = iam.list_users()

        for user in users['Users']:
            # Create/update identity in Elder
            # Store ARN, access keys metadata
            # Store MFA devices
            pass

    async def discover_roles(self):
        """Discover IAM roles"""
        # Create identity_groups for roles
        # Store trust policy in metadata
        pass

    async def discover_policies(self):
        """Discover IAM policies"""
        # Store as metadata on identities/groups
        # Analyze permissions
        pass
```

**`apps/connector/connectors/gcp_iam_connector.py`**

```python
class GCPIAMConnector(BaseConnector):
    """Connector for GCP IAM"""

    async def sync_iam(self):
        """Sync GCP IAM resources"""
        # Service Accounts â†’ Elder Identities
        # IAM Roles â†’ Elder Identity Groups
        # IAM Bindings â†’ Group membership
        # Organization Policy â†’ Metadata
        # Workload Identity Federation â†’ Metadata
        pass
```

**`apps/connector/connectors/k8s_iam_connector.py`**

```python
class K8sIAMConnector(BaseConnector):
    """Connector for Kubernetes RBAC"""

    def __init__(self, kubeconfig_path):
        super().__init__("k8s_iam")
        from kubernetes import client, config
        config.load_kube_config(kubeconfig_path)
        self.rbac_v1 = client.RbacAuthorizationV1Api()
        self.core_v1 = client.CoreV1Api()

    async def sync_iam(self):
        """Sync Kubernetes RBAC to Elder"""
        # ServiceAccounts â†’ Elder Identities
        # Roles/ClusterRoles â†’ Elder Identity Groups
        # RoleBindings/ClusterRoleBindings â†’ Group membership
        pass

    async def discover_service_accounts(self):
        """Discover K8s service accounts"""
        # List all service accounts across all namespaces
        pass

    async def discover_roles(self):
        """Discover K8s Roles and ClusterRoles"""
        # Analyze RBAC permissions
        pass
```

### ðŸ”µ CORE CONTAINER

**API Endpoints:**

**New File: `apps/api/api/v1/iam.py`**

- `GET /api/v1/iam/aws/users` - List AWS IAM users synced to Elder
- `GET /api/v1/iam/aws/roles` - List AWS IAM roles
- `GET /api/v1/iam/aws/policies` - List AWS IAM policies

- `GET /api/v1/iam/gcp/service-accounts` - List GCP service accounts
- `GET /api/v1/iam/gcp/roles` - List GCP IAM roles

- `GET /api/v1/iam/k8s/service-accounts` - List K8s service accounts
- `GET /api/v1/iam/k8s/roles` - List K8s roles

- `POST /api/v1/iam/sync` - Trigger IAM sync across all providers

**UI Components:**

1. `web/src/pages/IAMDashboard.tsx` - Overview of IAM entities across providers
2. `web/src/components/IAMPolicyViewer.tsx` - Visualize permission policies
3. `web/src/components/IAMEntityList.tsx` - List IAM users/roles/service accounts

---

## Phase 5: Cloud Auto-Discovery Completion (Weeks 9-12)

### ðŸŸ¢ CONNECTOR CONTAINER

**Expand Existing Connectors:**

**`apps/connector/connectors/aws_connector.py` (COMPLETE)**

```python
class AWSConnector(BaseConnector):
    """Complete AWS infrastructure discovery"""

    async def discover_all(self):
        """Discover all AWS resources across regions"""
        regions = settings.aws_regions.split(',')

        tasks = []
        for region in regions:
            tasks.extend([
                self.discover_ec2_instances(region),
                self.discover_vpcs(region),
                self.discover_subnets(region),
                self.discover_security_groups(region),
                self.discover_rds_instances(region),
                self.discover_s3_buckets(region),
                self.discover_load_balancers(region),
                self.discover_lambda_functions(region),
                self.discover_eks_clusters(region),
            ])

        await asyncio.gather(*tasks)

    async def discover_ec2_instances(self, region):
        """Discover EC2 instances â†’ compute/server or compute/virtualMachine"""
        ec2 = boto3.resource('ec2', region_name=region)

        for instance in ec2.instances.all():
            # Determine sub_type based on instance type
            sub_type = 'virtual_machine' if instance.instance_type.startswith('t') else 'server'

            # Create/update entity
            entity_data = {
                'name': instance.tags.get('Name', instance.id),
                'type': 'compute',
                'sub_type': sub_type,
                'external_id': instance.id,
                'external_platform': 'aws',
                'metadata': {
                    'instance_type': instance.instance_type,
                    'state': instance.state['Name'],
                    'availability_zone': instance.placement['AvailabilityZone'],
                    'private_ip': instance.private_ip_address,
                    'public_ip': instance.public_ip_address,
                    'tags': {tag['Key']: tag['Value'] for tag in instance.tags},
                }
            }

            await self.elder_client.create_or_update_entity(entity_data)

    async def discover_vpcs(self, region):
        """Discover VPCs â†’ datacenter/publicVPC or datacenter/privateVPC"""
        ec2 = boto3.client('ec2', region_name=region)
        vpcs = ec2.describe_vpcs()

        for vpc in vpcs['Vpcs']:
            # Determine if public or private based on internet gateway
            igws = ec2.describe_internet_gateways(Filters=[
                {'Name': 'attachment.vpc-id', 'Values': [vpc['VpcId']]}
            ])
            sub_type = 'public_vpc' if igws['InternetGateways'] else 'private_vpc'

            entity_data = {
                'name': vpc.get('Tags', {}).get('Name', vpc['VpcId']),
                'type': 'datacenter',
                'sub_type': sub_type,
                'external_id': vpc['VpcId'],
                'external_platform': 'aws',
                'metadata': {
                    'cidr_block': vpc['CidrBlock'],
                    'is_default': vpc['IsDefault'],
                }
            }

            await self.elder_client.create_or_update_entity(entity_data)

    async def discover_subnets(self, region):
        """Discover Subnets â†’ network/subnet"""
        # Similar pattern
        pass

    async def discover_security_groups(self, region):
        """Discover Security Groups â†’ network/firewall"""
        # Similar pattern
        pass

    async def discover_rds_instances(self, region):
        """Discover RDS â†’ storage/database"""
        rds = boto3.client('rds', region_name=region)
        instances = rds.describe_db_instances()

        for db in instances['DBInstances']:
            entity_data = {
                'name': db['DBInstanceIdentifier'],
                'type': 'storage',
                'sub_type': 'database',
                'external_id': db['DBInstanceIdentifier'],
                'metadata': {
                    'engine': db['Engine'],
                    'version': db['EngineVersion'],
                    'port': db['Endpoint']['Port'],
                }
            }
            await self.elder_client.create_or_update_entity(entity_data)

    async def discover_s3_buckets(self, region):
        """Discover S3 â†’ storage/other"""
        pass

    async def discover_load_balancers(self, region):
        """Discover ELB/ALB â†’ network/proxy"""
        pass

    async def discover_lambda_functions(self, region):
        """Discover Lambda â†’ compute/serverless"""
        pass

    async def discover_eks_clusters(self, region):
        """Discover EKS â†’ compute/kubernetes_cluster"""
        pass
```

**`apps/connector/connectors/gcp_connector.py` (COMPLETE)**

```python
class GCPConnector(BaseConnector):
    """Complete GCP infrastructure discovery"""

    async def discover_all(self):
        """Discover all GCP resources across projects"""
        projects = settings.gcp_project_ids.split(',')

        tasks = []
        for project in projects:
            tasks.extend([
                self.discover_compute_instances(project),
                self.discover_vpc_networks(project),
                self.discover_subnets(project),
                self.discover_firewall_rules(project),
                self.discover_cloud_sql(project),
                self.discover_cloud_storage(project),
                self.discover_load_balancers(project),
                self.discover_cloud_functions(project),
                self.discover_gke_clusters(project),
            ])

        await asyncio.gather(*tasks)

    async def discover_compute_instances(self, project):
        """Discover Compute Engine VMs â†’ compute/virtual_machine"""
        from google.cloud import compute_v1

        client = compute_v1.InstancesClient()

        # List instances across all zones
        for zone in self.get_zones(project):
            request = compute_v1.ListInstancesRequest(
                project=project,
                zone=zone
            )

            for instance in client.list(request=request):
                entity_data = {
                    'name': instance.name,
                    'type': 'compute',
                    'sub_type': 'virtual_machine',
                    'external_id': str(instance.id),
                    'external_platform': 'gcp',
                    'metadata': {
                        'machine_type': instance.machine_type,
                        'status': instance.status,
                        'zone': zone,
                    }
                }
                await self.elder_client.create_or_update_entity(entity_data)

    # Similar methods for VPC, Cloud SQL, GKE, etc.
```

**`apps/connector/connectors/azure_connector.py` (NEW)**

```python
class AzureConnector(BaseConnector):
    """Azure infrastructure discovery"""

    def __init__(self):
        super().__init__("azure")
        from azure.identity import DefaultAzureCredential
        from azure.mgmt.compute import ComputeManagementClient
        from azure.mgmt.network import NetworkManagementClient
        from azure.mgmt.storage import StorageManagementClient
        from azure.mgmt.sql import SqlManagementClient

        credential = DefaultAzureCredential()

        self.subscription_ids = settings.azure_subscription_ids.split(',')
        self.compute_clients = {
            sub: ComputeManagementClient(credential, sub)
            for sub in self.subscription_ids
        }
        self.network_clients = {
            sub: NetworkManagementClient(credential, sub)
            for sub in self.subscription_ids
        }

    async def discover_all(self):
        """Discover all Azure resources across subscriptions"""
        tasks = []
        for sub_id in self.subscription_ids:
            tasks.extend([
                self.discover_vms(sub_id),
                self.discover_vnets(sub_id),
                self.discover_subnets(sub_id),
                self.discover_nsgs(sub_id),
                self.discover_azure_sql(sub_id),
                self.discover_storage_accounts(sub_id),
                self.discover_load_balancers(sub_id),
                self.discover_functions(sub_id),
                self.discover_aks_clusters(sub_id),
            ])

        await asyncio.gather(*tasks)

    async def discover_vms(self, subscription_id):
        """Discover Azure VMs â†’ compute/virtual_machine"""
        compute_client = self.compute_clients[subscription_id]

        for vm in compute_client.virtual_machines.list_all():
            entity_data = {
                'name': vm.name,
                'type': 'compute',
                'sub_type': 'virtual_machine',
                'external_id': vm.id,
                'external_platform': 'azure',
                'metadata': {
                    'vm_size': vm.hardware_profile.vm_size,
                    'location': vm.location,
                    'os_type': vm.storage_profile.os_disk.os_type,
                }
            }
            await self.elder_client.create_or_update_entity(entity_data)

    # Similar methods for VNets, NSGs, Azure SQL, AKS, etc.
```

**Discovery Scheduling:**

**New File: `apps/connector/sync/discovery_scheduler.py`**

```python
from apscheduler.schedulers.asyncio import AsyncIOScheduler

class DiscoveryScheduler:
    """Schedule cloud discovery jobs"""

    def __init__(self):
        self.scheduler = AsyncIOScheduler()

    def schedule_aws_discovery(self):
        """Schedule AWS discovery"""
        interval = int(os.getenv('AWS_DISCOVERY_INTERVAL', 3600))
        self.scheduler.add_job(
            run_aws_discovery,
            'interval',
            seconds=interval,
            id='aws_discovery'
        )

    def schedule_gcp_discovery(self):
        """Schedule GCP discovery"""
        interval = int(os.getenv('GCP_DISCOVERY_INTERVAL', 3600))
        self.scheduler.add_job(
            run_gcp_discovery,
            'interval',
            seconds=interval,
            id='gcp_discovery'
        )

    def schedule_azure_discovery(self):
        """Schedule Azure discovery"""
        interval = int(os.getenv('AZURE_DISCOVERY_INTERVAL', 3600))
        self.scheduler.add_job(
            run_azure_discovery,
            'interval',
            seconds=interval,
            id='azure_discovery'
        )
```

### ðŸ”µ CORE CONTAINER

**Database Schema:**

**New File: `apps/api/models/discovery.py`**

```python
# apps/api/models/pydal_models.py
db.define_table(
    "discovery_jobs",
    Field("name", "string", length=255, notnull=True),
    Field("provider", "string", length=50, notnull=True),  # aws, gcp, azure
    Field("config_json", "json", notnull=True),  # Provider-specific config
    Field("schedule_interval", "integer", default=3600),  # Seconds
    Field("enabled", "boolean", default=True),
    Field("last_run_at", "datetime"),
    Field("next_run_at", "datetime"),
    Field("created_at", "datetime", default=datetime.utcnow),
)

db.define_table(
    "cloud_accounts",
    Field("name", "string", length=255, notnull=True),
    Field("provider", "string", length=50, notnull=True),
    Field("credentials_json", "json", notnull=True),  # Encrypted credentials
    Field("organization_id", "reference organizations"),  # Scope to OU
    Field("enabled", "boolean", default=True),
    Field("created_at", "datetime", default=datetime.utcnow),
)

db.define_table(
    "discovery_history",
    Field("job_id", "reference discovery_jobs", notnull=True),
    Field("started_at", "datetime", default=datetime.utcnow),
    Field("completed_at", "datetime"),
    Field("status", "string", length=20),  # running, completed, failed
    Field("entities_discovered", "integer", default=0),
    Field("entities_created", "integer", default=0),
    Field("entities_updated", "integer", default=0),
    Field("error_message", "text"),
)
```

**API Endpoints:**

**New File: `apps/api/api/v1/discovery.py`**

- `POST /api/v1/discovery/jobs` - Create discovery job
- `GET /api/v1/discovery/jobs` - List discovery jobs
- `GET /api/v1/discovery/jobs/{id}` - Get job details
- `PATCH /api/v1/discovery/jobs/{id}` - Update job
- `DELETE /api/v1/discovery/jobs/{id}` - Delete job
- `POST /api/v1/discovery/jobs/{id}/run` - Trigger discovery now
- `GET /api/v1/discovery/history` - Discovery execution history
- `GET /api/v1/discovery/history/{id}` - Specific execution details

- `POST /api/v1/cloud-accounts` - Add cloud account
- `GET /api/v1/cloud-accounts` - List accounts
- `PATCH /api/v1/cloud-accounts/{id}` - Update account
- `DELETE /api/v1/cloud-accounts/{id}` - Delete account
- `POST /api/v1/cloud-accounts/{id}/test` - Test connection

**UI Components:**

1. `web/src/pages/CloudDiscovery.tsx` - Discovery job management
2. `web/src/pages/CloudAccounts.tsx` - Cloud account configuration
3. `web/src/pages/DiscoveryHistory.tsx` - View discovery execution logs
4. `web/src/components/DiscoveryJobForm.tsx` - Create/edit discovery job
5. `web/src/components/CloudAccountForm.tsx` - Add cloud account credentials

---

## Phase 6: Directory Integration Completion (Weeks 11-13)

### ðŸŸ¢ CONNECTOR CONTAINER

**Complete Existing Connectors:**

**`apps/connector/connectors/ldap_connector.py` (COMPLETE)**

```python
class LDAPConnector(BaseConnector):
    """Complete LDAP/AD connector with full OU hierarchy"""

    async def sync_directory(self):
        """Full directory synchronization"""
        await self.sync_organizational_units()
        await self.sync_users()
        await self.sync_groups()

    async def sync_organizational_units(self):
        """Sync LDAP OUs to Elder Organizations"""
        # Search for organizationalUnit objects
        # Build hierarchy from DN structure
        # Create nested organizations in Elder

        search_base = settings.ldap_base_dn
        search_filter = '(objectClass=organizationalUnit)'

        self.ldap_conn.search(
            search_base,
            search_filter,
            SUBTREE,
            attributes=['ou', 'description']
        )

        for entry in self.ldap_conn.entries:
            dn = entry.entry_dn
            ou_name = entry.ou.value

            # Parse DN to determine parent
            parent_dn = self.get_parent_dn(dn)
            parent_org_id = self.ou_cache.get(parent_dn)

            # Create organization
            org_data = {
                'name': ou_name,
                'parent_id': parent_org_id,
                'type': 'ou',
                'metadata': {
                    'ldap_dn': dn,
                    'description': entry.description.value if entry.description else None
                }
            }

            org_id = await self.elder_client.create_or_update_organization(org_data)
            self.ou_cache[dn] = org_id

    async def sync_users(self):
        """Sync LDAP users to Elder Identities"""
        search_filter = '(objectClass=user)'

        self.ldap_conn.search(
            settings.ldap_base_dn,
            search_filter,
            SUBTREE,
            attributes=['sAMAccountName', 'mail', 'givenName', 'sn', 'memberOf']
        )

        for entry in self.ldap_conn.entries:
            # Map LDAP attributes to Elder identity
            identity_data = {
                'username': entry.sAMAccountName.value,
                'email': entry.mail.value if entry.mail else None,
                'first_name': entry.givenName.value if entry.givenName else None,
                'last_name': entry.sn.value if entry.sn else None,
                'type': 'user',
                'metadata': {
                    'ldap_dn': entry.entry_dn,
                    'member_of': [group.value for group in entry.memberOf]
                }
            }

            await self.elder_client.create_or_update_identity(identity_data)

    async def sync_groups(self):
        """Sync LDAP groups to Elder Identity Groups"""
        # Similar to users, but create identity_groups
        pass
```

**`apps/connector/connectors/google_workspace_connector.py` (COMPLETE)**

```python
class GoogleWorkspaceConnector(BaseConnector):
    """Complete Google Workspace connector"""

    async def sync_workspace(self):
        """Full Google Workspace synchronization"""
        await self.sync_organizational_units()
        await self.sync_users()
        await self.sync_groups()

    async def sync_organizational_units(self):
        """Sync Google Workspace OUs to Elder Organizations"""
        from googleapiclient.discovery import build

        service = build('admin', 'directory_v1', credentials=self.credentials)

        # Get all organizational units
        results = service.orgunits().list(
            customerId='my_customer',
            type='all'
        ).execute()

        for ou in results.get('organizationUnits', []):
            # Parse OU path to determine parent
            parent_path = '/'.join(ou['orgUnitPath'].split('/')[:-1]) or '/'
            parent_org_id = self.ou_cache.get(parent_path)

            org_data = {
                'name': ou['name'],
                'parent_id': parent_org_id,
                'type': 'ou',
                'metadata': {
                    'workspace_ou_path': ou['orgUnitPath'],
                    'description': ou.get('description')
                }
            }

            org_id = await self.elder_client.create_or_update_organization(org_data)
            self.ou_cache[ou['orgUnitPath']] = org_id

    async def sync_users(self):
        """Sync Google Workspace users to Elder Identities"""
        # Use Admin SDK to list users
        # Map to Elder identities
        pass

    async def sync_groups(self):
        """Sync Google Workspace groups to Elder Identity Groups"""
        pass
```

**New File: `apps/connector/connectors/azure_ad_connector.py`**

```python
class AzureADConnector(BaseConnector):
    """Azure AD (Entra ID) connector"""

    def __init__(self):
        super().__init__("azure_ad")
        from azure.identity import DefaultAzureCredential
        from msgraph.core import GraphClient

        credential = DefaultAzureCredential()
        self.client = GraphClient(credential=credential)

    async def sync_azure_ad(self):
        """Full Azure AD synchronization"""
        await self.sync_directory_structure()
        await self.sync_users()
        await self.sync_groups()

    async def sync_directory_structure(self):
        """Sync Azure AD Administrative Units to Elder Organizations"""
        # Azure AD Tenants â†’ Top-level organizations
        # Administrative Units â†’ Child organizations
        pass

    async def sync_users(self):
        """Sync Azure AD users to Elder Identities"""
        # Use Microsoft Graph API
        users = self.client.get('/users')

        for user in users.json()['value']:
            identity_data = {
                'username': user['userPrincipalName'],
                'email': user['mail'],
                'first_name': user['givenName'],
                'last_name': user['surname'],
                'type': 'user',
                'metadata': {
                    'azure_ad_id': user['id'],
                    'job_title': user.get('jobTitle'),
                    'department': user.get('department'),
                }
            }

            await self.elder_client.create_or_update_identity(identity_data)

    async def sync_groups(self):
        """Sync Azure AD groups to Elder Identity Groups"""
        pass
```

### ðŸ”µ CORE CONTAINER

**API Endpoints:**

**New File: `apps/api/api/v1/directory.py`**

- `POST /api/v1/directory/sync` - Trigger directory sync
- `GET /api/v1/directory/status` - Get sync status for all directory sources
- `POST /api/v1/directory/ldap/sync` - Sync LDAP specifically
- `POST /api/v1/directory/google-workspace/sync` - Sync Google Workspace
- `POST /api/v1/directory/azure-ad/sync` - Sync Azure AD

**UI Components:**

1. `web/src/pages/DirectorySync.tsx` - Configure directory synchronization
2. `web/src/components/DirectorySyncStatus.tsx` - View sync status

---

## Phase 7: Database Enhancement (Weeks 13-14)

### ðŸ”µ CORE CONTAINER

**Update Database Layer:**

**File: `apps/api/database.py`**

```python
from pydal import DAL, Field
import os
from typing import List, Optional

class ElderDatabase:
    """Enhanced database layer with replica support"""

    def __init__(self):
        self.primary_uri = os.getenv('DATABASE_URL')
        self.replica_uris = self._parse_replica_urls()
        self.use_replicas = os.getenv('DATABASE_USE_REPLICAS', 'false').lower() == 'true'

        # Primary database connection (writes)
        self.db_write = DAL(
            self.primary_uri,
            pool_size=int(os.getenv('DATABASE_POOL_SIZE', 10)),
            migrate_enabled=True
        )

        # Replica connections (reads)
        self.db_read_pool = []
        if self.use_replicas and self.replica_uris:
            for replica_uri in self.replica_uris:
                db_read = DAL(
                    replica_uri,
                    pool_size=int(os.getenv('DATABASE_POOL_SIZE', 10)),
                    migrate_enabled=False  # Never migrate on replicas
                )
                self.db_read_pool.append(db_read)

        self.read_index = 0  # Round-robin index

    def _parse_replica_urls(self) -> List[str]:
        """Parse comma-separated replica URLs"""
        replica_str = os.getenv('DATABASE_REPLICA_URLS', '')
        if not replica_str:
            return []
        return [url.strip() for url in replica_str.split(',')]

    def get_write_db(self):
        """Get database connection for writes"""
        return self.db_write

    def get_read_db(self):
        """Get database connection for reads (load-balanced)"""
        if not self.use_replicas or not self.db_read_pool:
            # Fallback to primary if no replicas
            return self.db_write

        # Round-robin load balancing
        db = self.db_read_pool[self.read_index]
        self.read_index = (self.read_index + 1) % len(self.db_read_pool)

        # Test connection, fallback to primary if replica unavailable
        try:
            db.executesql("SELECT 1")
            return db
        except Exception:
            return self.db_write

# Global database instance
elder_db = ElderDatabase()

def get_db(for_write=False):
    """Get appropriate database connection"""
    if for_write:
        return elder_db.get_write_db()
    else:
        return elder_db.get_read_db()
```

**MariaDB Galera Support:**

```python
# apps/api/database.py - Add Galera-specific connection handling

def _init_galera_cluster(self):
    """Initialize MariaDB Galera cluster connections"""
    galera_nodes = os.getenv('MARIADB_GALERA_NODES', '')
    if not galera_nodes:
        return

    node_uris = [url.strip() for url in galera_nodes.split(',')]

    # Test each node for wsrep_ready status
    for node_uri in node_uris:
        db = DAL(node_uri)
        try:
            result = db.executesql("SHOW STATUS LIKE 'wsrep_ready'")
            if result and result[0][1] == 'ON':
                self.db_read_pool.append(db)
        except Exception as e:
            logger.warning(f"Galera node {node_uri} unavailable: {e}")
```

**Environment Variables:**

```bash
# Read replicas for PostgreSQL/MySQL
DATABASE_REPLICA_URLS=postgresql://user:pass@replica1:5432/elder,postgresql://user:pass@replica2:5432/elder
DATABASE_USE_REPLICAS=true

# MariaDB Galera cluster
MARIADB_GALERA_NODES=mariadb://user:pass@node1:3306/elder,mariadb://user:pass@node2:3306/elder,mariadb://user:pass@node3:3306/elder
```

---

## Phase 8: Audit System Enhancement (Weeks 14-15)

### ðŸ”µ CORE CONTAINER

**Expand Audit Logging:**

**Update: `apps/api/models/audit.py`**

```python
class AuditResourceType(enum.Enum):
    """Expanded resource types for auditing"""
    ENTITY = "entity"
    ORGANIZATION = "organization"
    IDENTITY = "identity"
    IDENTITY_GROUP = "identity_group"
    DEPENDENCY = "dependency"
    ROLE = "role"
    PERMISSION = "permission"
    AUTH = "auth"
    ISSUE = "issue"
    SECRET = "secret"  # NEW
    KEY = "key"  # NEW
    DISCOVERY_JOB = "discovery_job"  # NEW
    CLOUD_ACCOUNT = "cloud_account"  # NEW
    WEBHOOK = "webhook"  # NEW
    NOTIFICATION = "notification"  # NEW
```

**New Table: Audit Retention Policy**

```python
# apps/api/models/pydal_models.py
db.define_table(
    "audit_retention_policies",
    Field("resource_type", "string", length=50, notnull=True),
    Field("retention_days", "integer", default=90),  # 0 = permanent
    Field("enabled", "boolean", default=True),
    Field("created_at", "datetime", default=datetime.utcnow),
)
```

**API Endpoints:**

**Update: `apps/api/api/v1/audit.py`**

- `GET /api/v1/audit` - List audit logs with advanced filters
  - Query params: `resource_type`, `action`, `identity_id`, `start_date`, `end_date`, `page`, `per_page`
- `GET /api/v1/audit/{id}` - Get specific audit entry
- `POST /api/v1/audit/export` - Export audit logs (JSON/CSV)
- `POST /api/v1/audit/retention` - Configure retention policies
- `GET /api/v1/audit/retention` - List retention policies
- `GET /api/v1/audit/reports/soc2` - Generate SOC2 compliance report
- `GET /api/v1/audit/reports/iso27001` - Generate ISO27001 compliance report

**Compliance Reports:**

```python
# apps/api/services/compliance_reports.py

class ComplianceReportGenerator:
    """Generate compliance audit reports"""

    async def generate_soc2_report(self, start_date, end_date):
        """Generate SOC2 audit report"""
        # SOC2 Trust Principles:
        # - Security: Auth attempts, permission changes
        # - Availability: System access logs
        # - Processing Integrity: Data modifications
        # - Confidentiality: Secret access logs
        # - Privacy: Identity data access

        report = {
            'report_type': 'SOC2',
            'period': {'start': start_date, 'end': end_date},
            'sections': {
                'security': await self._get_security_events(start_date, end_date),
                'availability': await self._get_availability_events(start_date, end_date),
                'processing_integrity': await self._get_data_modification_events(start_date, end_date),
                'confidentiality': await self._get_confidential_access_events(start_date, end_date),
                'privacy': await self._get_privacy_events(start_date, end_date),
            }
        }

        return report
```

**UI Components:**

1. `web/src/pages/AuditViewer.tsx` - Search and filter audit logs
2. `web/src/pages/AuditRetention.tsx` - Configure retention policies
3. `web/src/pages/ComplianceReports.tsx` - Generate and download compliance reports
4. `web/src/components/AuditLogEntry.tsx` - Display single audit entry with details

---

## Phase 9: Webhook & Notification System (Weeks 15-16)

### ðŸ”µ CORE CONTAINER

**Database Schema:**

```python
# apps/api/models/pydal_models.py
db.define_table(
    "webhooks",
    Field("name", "string", length=255, notnull=True),
    Field("url", "string", length=500, notnull=True),
    Field("secret", "string", length=255),  # For HMAC signature
    Field("events", "list:string"),  # entity.created, entity.updated, etc.
    Field("enabled", "boolean", default=True),
    Field("organization_id", "reference organizations"),  # Optional: scope to OU
    Field("created_at", "datetime", default=datetime.utcnow),
)

db.define_table(
    "webhook_deliveries",
    Field("webhook_id", "reference webhooks", notnull=True),
    Field("event_type", "string", length=50, notnull=True),
    Field("payload", "json", notnull=True),
    Field("response_status", "integer"),
    Field("response_body", "text"),
    Field("delivered_at", "datetime", default=datetime.utcnow),
    Field("success", "boolean", default=False),
)

db.define_table(
    "notification_rules",
    Field("name", "string", length=255, notnull=True),
    Field("channel", "string", length=50, notnull=True),  # email, slack, teams
    Field("events", "list:string"),  # Events to notify on
    Field("config_json", "json", notnull=True),  # Channel-specific config
    Field("enabled", "boolean", default=True),
    Field("organization_id", "reference organizations"),
    Field("created_at", "datetime", default=datetime.utcnow),
)
```

**Webhook Delivery Service:**

**New File: `apps/api/services/webhook_delivery.py`**

```python
import hmac
import hashlib
import httpx
from typing import Dict, Any

class WebhookDeliveryService:
    """Deliver webhooks to external systems"""

    async def deliver_webhook(self, webhook_id: int, event_type: str, payload: Dict[str, Any]):
        """Deliver webhook with signature"""
        db = get_db()
        webhook = db(db.webhooks.id == webhook_id).select().first()

        if not webhook or not webhook.enabled:
            return

        # Create HMAC signature
        signature = self._create_signature(webhook.secret, payload)

        # Deliver webhook
        async with httpx.AsyncClient() as client:
            try:
                response = await client.post(
                    webhook.url,
                    json=payload,
                    headers={
                        'X-Elder-Signature': signature,
                        'X-Elder-Event': event_type,
                        'Content-Type': 'application/json'
                    },
                    timeout=30.0
                )

                # Log delivery
                db.webhook_deliveries.insert(
                    webhook_id=webhook_id,
                    event_type=event_type,
                    payload=payload,
                    response_status=response.status_code,
                    response_body=response.text[:1000],
                    success=response.status_code < 300
                )

            except Exception as e:
                # Log failure
                db.webhook_deliveries.insert(
                    webhook_id=webhook_id,
                    event_type=event_type,
                    payload=payload,
                    response_status=0,
                    response_body=str(e),
                    success=False
                )

    def _create_signature(self, secret: str, payload: Dict[str, Any]) -> str:
        """Create HMAC-SHA256 signature"""
        import json
        payload_bytes = json.dumps(payload, sort_keys=True).encode('utf-8')
        signature = hmac.new(
            secret.encode('utf-8'),
            payload_bytes,
            hashlib.sha256
        ).hexdigest()
        return f"sha256={signature}"
```

**Notification Service:**

**New File: `apps/api/services/notification_service.py`**

```python
import smtplib
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart

class NotificationService:
    """Unified notification service"""

    async def send_notification(self, rule_id: int, event_type: str, data: Dict[str, Any]):
        """Send notification based on rule"""
        db = get_db()
        rule = db(db.notification_rules.id == rule_id).select().first()

        if not rule or not rule.enabled:
            return

        if rule.channel == 'email':
            await self._send_email(rule.config_json, event_type, data)
        elif rule.channel == 'slack':
            await self._send_slack(rule.config_json, event_type, data)
        elif rule.channel == 'teams':
            await self._send_teams(rule.config_json, event_type, data)

    async def _send_email(self, config: Dict, event_type: str, data: Dict):
        """Send email notification"""
        smtp_host = os.getenv('SMTP_HOST')
        smtp_port = int(os.getenv('SMTP_PORT', 587))
        smtp_user = os.getenv('SMTP_USER')
        smtp_password = os.getenv('SMTP_PASSWORD')

        msg = MIMEMultipart()
        msg['From'] = smtp_user
        msg['To'] = config['to']
        msg['Subject'] = f"Elder Alert: {event_type}"

        body = self._format_email_body(event_type, data)
        msg.attach(MIMEText(body, 'html'))

        with smtplib.SMTP(smtp_host, smtp_port) as server:
            server.starttls()
            server.login(smtp_user, smtp_password)
            server.send_message(msg)

    async def _send_slack(self, config: Dict, event_type: str, data: Dict):
        """Send Slack notification"""
        webhook_url = config.get('webhook_url') or os.getenv('SLACK_WEBHOOK_URL')

        payload = {
            "text": f"*Elder Alert: {event_type}*",
            "blocks": [
                {
                    "type": "section",
                    "text": {
                        "type": "mrkdwn",
                        "text": self._format_slack_message(event_type, data)
                    }
                }
            ]
        }

        async with httpx.AsyncClient() as client:
            await client.post(webhook_url, json=payload)

    async def _send_teams(self, config: Dict, event_type: str, data: Dict):
        """Send Microsoft Teams notification"""
        webhook_url = config.get('webhook_url') or os.getenv('TEAMS_WEBHOOK_URL')

        payload = {
            "@type": "MessageCard",
            "@context": "http://schema.org/extensions",
            "summary": f"Elder Alert: {event_type}",
            "sections": [{
                "activityTitle": f"Elder Alert: {event_type}",
                "text": self._format_teams_message(event_type, data)
            }]
        }

        async with httpx.AsyncClient() as client:
            await client.post(webhook_url, json=payload)
```

**API Endpoints:**

**New File: `apps/api/api/v1/webhooks.py`**

- `POST /api/v1/webhooks` - Create webhook
- `GET /api/v1/webhooks` - List webhooks
- `GET /api/v1/webhooks/{id}` - Get webhook details
- `PATCH /api/v1/webhooks/{id}` - Update webhook
- `DELETE /api/v1/webhooks/{id}` - Delete webhook
- `POST /api/v1/webhooks/{id}/test` - Test webhook delivery
- `GET /api/v1/webhooks/{id}/deliveries` - Get delivery history

**New File: `apps/api/api/v1/notifications.py`**

- `POST /api/v1/notifications` - Create notification rule
- `GET /api/v1/notifications` - List notification rules
- `PATCH /api/v1/notifications/{id}` - Update rule
- `DELETE /api/v1/notifications/{id}` - Delete rule
- `POST /api/v1/notifications/email/test` - Test email delivery
- `POST /api/v1/notifications/slack/test` - Test Slack delivery
- `POST /api/v1/notifications/teams/test` - Test Teams delivery

**UI Components:**

1. `web/src/pages/Webhooks.tsx` - Manage webhooks
2. `web/src/components/WebhookForm.tsx` - Create/edit webhook
3. `web/src/components/WebhookDeliveries.tsx` - View delivery logs
4. `web/src/pages/NotificationRules.tsx` - Manage notification rules
5. `web/src/components/NotificationRuleForm.tsx` - Create/edit notification rule

---

## Phase 10: Advanced Search & Data Management (Weeks 16-17)

### ðŸ”µ CORE CONTAINER

**Search System:**

**New File: `apps/api/services/search_service.py`**

```python
class SearchService:
    """Full-text search across all Elder resources"""

    async def search(self, query: str, filters: Dict = None):
        """Search entities, organizations, identities, issues"""
        db = get_db()

        results = {
            'entities': [],
            'organizations': [],
            'identities': [],
            'issues': [],
        }

        # Search entities
        entity_query = (db.entities.name.contains(query)) | \
                       (db.entities.description.contains(query))

        if filters and 'entity_type' in filters:
            entity_query &= (db.entities.type == filters['entity_type'])

        results['entities'] = db(entity_query).select().as_list()

        # Similar for organizations, identities, issues
        # ...

        return results
```

**Saved Searches:**

```python
# apps/api/models/pydal_models.py
db.define_table(
    "saved_searches",
    Field("name", "string", length=255, notnull=True),
    Field("query", "string", length=500, notnull=True),
    Field("filters", "json"),
    Field("identity_id", "reference identities", notnull=True),
    Field("created_at", "datetime", default=datetime.utcnow),
)
```

**API Endpoints:**

**New File: `apps/api/api/v1/search.py`**

- `GET /api/v1/search?q={query}&type={type}&filters={json}` - Full-text search
- `POST /api/v1/search/saved` - Save search query
- `GET /api/v1/search/saved` - List saved searches
- `DELETE /api/v1/search/saved/{id}` - Delete saved search
- `GET /api/v1/search/saved/{id}/execute` - Execute saved search

**Data Management:**

**Backup Service:**

**New File: `apps/api/services/backup_service.py`**

```python
import boto3
import gzip
import json
from datetime import datetime

class BackupService:
    """Database backup and restore"""

    async def create_backup(self):
        """Create full database backup"""
        db = get_db(for_write=True)

        backup_data = {
            'timestamp': datetime.utcnow().isoformat(),
            'version': '1.2.0',
            'tables': {}
        }

        # Backup all tables
        tables = ['entities', 'organizations', 'identities', 'dependencies',
                  'issues', 'secrets', 'keys', 'audit_logs']

        for table_name in tables:
            table = db[table_name]
            backup_data['tables'][table_name] = table.select().as_list()

        # Compress backup
        backup_json = json.dumps(backup_data)
        backup_compressed = gzip.compress(backup_json.encode('utf-8'))

        # Upload to S3 (if enabled)
        if os.getenv('BACKUP_S3_BUCKET'):
            s3 = boto3.client('s3')
            s3.put_object(
                Bucket=os.getenv('BACKUP_S3_BUCKET'),
                Key=f"backups/elder-{datetime.utcnow().strftime('%Y%m%d-%H%M%S')}.json.gz",
                Body=backup_compressed
            )

        return backup_data

    async def restore_backup(self, backup_file):
        """Restore from backup"""
        # Decompress and load backup
        # Restore tables
        pass
```

**Export Service:**

**New File: `apps/api/services/export_service.py`**

```python
import csv
import json
from io import StringIO

class ExportService:
    """Export data to JSON/CSV"""

    async def export_entities(self, format='json', filters=None):
        """Export entities"""
        db = get_db()
        query = db.entities

        if filters:
            if 'type' in filters:
                query = query(db.entities.type == filters['type'])

        entities = query.select().as_list()

        if format == 'json':
            return json.dumps(entities, indent=2)
        elif format == 'csv':
            return self._entities_to_csv(entities)

    def _entities_to_csv(self, entities):
        """Convert entities to CSV"""
        output = StringIO()
        if not entities:
            return ""

        fieldnames = entities[0].keys()
        writer = csv.DictWriter(output, fieldnames=fieldnames)
        writer.writeheader()
        writer.writerows(entities)

        return output.getvalue()
```

**Import Service:**

**New File: `apps/api/services/import_service.py`**

```python
class ImportService:
    """Import data from JSON/CSV"""

    async def import_entities(self, file_content, format='json', validate=True):
        """Import entities with validation"""
        if format == 'json':
            data = json.loads(file_content)
        elif format == 'csv':
            data = self._csv_to_entities(file_content)

        # Validate data
        if validate:
            errors = self._validate_entities(data)
            if errors:
                return {'success': False, 'errors': errors}

        # Import entities
        db = get_db(for_write=True)
        imported = 0

        for entity in data:
            db.entities.insert(**entity)
            imported += 1

        return {'success': True, 'imported': imported}
```

**API Endpoints:**

**New File: `apps/api/api/v1/backup.py`**

- `POST /api/v1/backup` - Create backup
- `GET /api/v1/backup` - List backups
- `POST /api/v1/restore` - Restore from backup

**New File: `apps/api/api/v1/export.py`**

- `POST /api/v1/export` - Export data (JSON/CSV)
- `POST /api/v1/import` - Import data
- `POST /api/v1/import/validate` - Validate import data

**UI Components:**

1. `web/src/pages/AdvancedSearch.tsx` - Search interface with filters
2. `web/src/pages/SavedSearches.tsx` - Manage saved searches
3. `web/src/pages/BackupManager.tsx` - Backup/restore interface
4. `web/src/pages/DataExport.tsx` - Export data
5. `web/src/pages/DataImport.tsx` - Import/migration interface

---

## Phase 11: Testing & Documentation (Weeks 17-18)

### Testing

**ðŸ”µ CORE CONTAINER - Unit Tests:**

- `tests/api/test_entity_subtypes.py` - Entity sub-type tests
- `tests/api/test_secrets.py` - Secrets API tests
- `tests/api/test_keys.py` - Keys API tests
- `tests/api/test_iam.py` - IAM integration tests
- `tests/api/test_discovery.py` - Discovery job tests
- `tests/api/test_directory.py` - Directory sync tests
- `tests/api/test_audit.py` - Audit system tests
- `tests/api/test_webhooks.py` - Webhook delivery tests
- `tests/api/test_notifications.py` - Notification tests
- `tests/api/test_search.py` - Search tests
- `tests/api/test_backup.py` - Backup/restore tests

**ðŸŸ¢ CONNECTOR CONTAINER - Unit Tests:**

- `tests/connector/test_aws_connector.py` - AWS discovery tests
- `tests/connector/test_gcp_connector.py` - GCP discovery tests
- `tests/connector/test_azure_connector.py` - Azure discovery tests
- `tests/connector/test_aws_iam_connector.py` - AWS IAM tests
- `tests/connector/test_gcp_iam_connector.py` - GCP IAM tests
- `tests/connector/test_k8s_iam_connector.py` - Kubernetes IAM tests
- `tests/connector/test_aws_secrets_connector.py` - AWS Secrets tests
- `tests/connector/test_gcp_secrets_connector.py` - GCP Secrets tests
- `tests/connector/test_infisical_connector.py` - Infisical tests
- `tests/connector/test_ldap_connector.py` - LDAP sync tests
- `tests/connector/test_google_workspace_connector.py` - Google Workspace tests
- `tests/connector/test_azure_ad_connector.py` - Azure AD tests

**Integration Tests:**

- End-to-end discovery workflows
- Full secret lifecycle (sync, mask, unmask)
- Key management workflows
- IAM sync and identity creation
- Directory sync with OU hierarchy
- Webhook delivery and retry
- Notification delivery across channels
- Backup and restore workflows

### Documentation

**New Files:**

1. `docs/ENTITIES.md` - Entity types and sub-types reference
2. `docs/SECRETS.md` - Secrets management guide with provider setup
3. `docs/KEYS.md` - Key management guide
4. `docs/CLOUD_DISCOVERY.md` - Cloud auto-discovery setup for AWS/GCP/Azure
5. `docs/IAM_INTEGRATION.md` - IAM integration guide
6. `docs/DIRECTORY_SYNC.md` - LDAP/Google Workspace/Azure AD sync guide
7. `docs/WEBHOOKS.md` - Webhook integration guide
8. `docs/NOTIFICATIONS.md` - Notification setup guide
9. `docs/BACKUP_RESTORE.md` - Backup and restore procedures

**Update Existing:**

- `docs/DATABASE.md` - Add Galera/replica support documentation
- `README.md` - Update with v1.2.0 features
- `docs/RELEASE_NOTES.md` - Prepend v1.2.0 release notes

---

## Environment Variables Summary

### ðŸŸ¢ CONNECTOR CONTAINER (40 variables)

**Cloud Discovery:**
```bash
AWS_DISCOVERY_ENABLED=true
AWS_DISCOVERY_INTERVAL=3600
AWS_REGIONS=us-east-1,us-west-2,eu-west-1

GCP_DISCOVERY_ENABLED=true
GCP_PROJECT_IDS=project1,project2
GCP_DISCOVERY_INTERVAL=3600

AZURE_DISCOVERY_ENABLED=true
AZURE_SUBSCRIPTION_IDS=sub1,sub2
AZURE_DISCOVERY_INTERVAL=3600
```

**IAM Integration:**
```bash
AWS_IAM_SYNC_ENABLED=true
GCP_IAM_SYNC_ENABLED=true
K8S_IAM_SYNC_ENABLED=true
K8S_KUBECONFIG_PATH=/path/to/kubeconfig
IAM_SYNC_INTERVAL=7200
```

**Secrets Management:**
```bash
AWS_SECRETS_MANAGER_ENABLED=true
GCP_SECRETS_ENABLED=true
INFISICAL_ENABLED=true
INFISICAL_URL=https://app.infisical.com
SECRETS_SYNC_INTERVAL=3600
```

**Keys Management:**
```bash
AWS_KMS_ENABLED=true
GCP_KMS_ENABLED=true
KEYS_SYNC_INTERVAL=3600
```

**Directory Sync:**
```bash
LDAP_SYNC_ENABLED=true
LDAP_SYNC_INTERVAL=3600
GOOGLE_WORKSPACE_SYNC_ENABLED=true
GOOGLE_WORKSPACE_SYNC_INTERVAL=3600
AZURE_AD_SYNC_ENABLED=true
AZURE_AD_SYNC_INTERVAL=3600
```

### ðŸ”µ CORE CONTAINER (15 variables)

**Database:**
```bash
DATABASE_REPLICA_URLS=postgresql://user:pass@replica1:5432/elder,postgresql://user:pass@replica2:5432/elder
DATABASE_USE_REPLICAS=true
MARIADB_GALERA_NODES=mariadb://user:pass@node1:3306/elder,mariadb://user:pass@node2:3306/elder
DATABASE_POOL_SIZE=10
```

**Notifications:**
```bash
SMTP_HOST=smtp.gmail.com
SMTP_PORT=587
SMTP_USER=alerts@company.com
SMTP_PASSWORD=secret
SLACK_WEBHOOK_URL=https://hooks.slack.com/services/XXX
TEAMS_WEBHOOK_URL=https://outlook.office.com/webhook/XXX
```

**Search:**
```bash
ELASTICSEARCH_ENABLED=false
ELASTICSEARCH_URL=http://elasticsearch:9200
```

**Backup:**
```bash
BACKUP_ENABLED=true
BACKUP_INTERVAL=86400
BACKUP_RETENTION_DAYS=30
BACKUP_S3_BUCKET=elder-backups
```

---

## File Manifest

### New Files (85 total)

**ðŸ”µ CORE CONTAINER:**

**Models (6):**
- `apps/api/models/secret.py`
- `apps/api/models/key.py`
- `apps/api/models/discovery.py`
- `apps/api/migrations/002_entity_subtypes.py`
- `apps/api/migrations/003_secrets_keys.py`
- `apps/api/migrations/004_discovery_webhooks.py`

**API Endpoints (10):**
- `apps/api/api/v1/secrets.py`
- `apps/api/api/v1/keys.py`
- `apps/api/api/v1/iam.py`
- `apps/api/api/v1/discovery.py`
- `apps/api/api/v1/directory.py`
- `apps/api/api/v1/webhooks.py`
- `apps/api/api/v1/notifications.py`
- `apps/api/api/v1/search.py`
- `apps/api/api/v1/backup.py`
- `apps/api/api/v1/export.py`

**Services (7):**
- `apps/api/services/webhook_delivery.py`
- `apps/api/services/notification_service.py`
- `apps/api/services/compliance_reports.py`
- `apps/api/services/search_service.py`
- `apps/api/services/backup_service.py`
- `apps/api/services/export_service.py`
- `apps/api/services/import_service.py`

**Frontend (20):**
- `web/src/components/EntityTypeSelector.tsx`
- `web/src/pages/EntityTypes.tsx`
- `web/src/pages/SecretProviders.tsx`
- `web/src/components/SecretProviderWizard.tsx`
- `web/src/pages/Secrets.tsx`
- `web/src/components/SecretDetail.tsx`
- `web/src/components/SecretAccessControl.tsx`
- `web/src/components/SecretAccessLog.tsx`
- `web/src/pages/KeyProviders.tsx`
- `web/src/components/KeyProviderWizard.tsx`
- `web/src/pages/Keys.tsx`
- `web/src/components/KeyDetail.tsx`
- `web/src/pages/IAMDashboard.tsx`
- `web/src/components/IAMPolicyViewer.tsx`
- `web/src/components/IAMEntityList.tsx`
- `web/src/pages/CloudDiscovery.tsx`
- `web/src/pages/CloudAccounts.tsx`
- `web/src/pages/DiscoveryHistory.tsx`
- `web/src/components/DiscoveryJobForm.tsx`
- `web/src/components/CloudAccountForm.tsx`
- `web/src/pages/DirectorySync.tsx`
- `web/src/components/DirectorySyncStatus.tsx`
- `web/src/pages/AuditViewer.tsx`
- `web/src/pages/AuditRetention.tsx`
- `web/src/pages/ComplianceReports.tsx`
- `web/src/components/AuditLogEntry.tsx`
- `web/src/pages/Webhooks.tsx`
- `web/src/components/WebhookForm.tsx`
- `web/src/components/WebhookDeliveries.tsx`
- `web/src/pages/NotificationRules.tsx`
- `web/src/components/NotificationRuleForm.tsx`
- `web/src/pages/AdvancedSearch.tsx`
- `web/src/pages/SavedSearches.tsx`
- `web/src/pages/BackupManager.tsx`
- `web/src/pages/DataExport.tsx`
- `web/src/pages/DataImport.tsx`

**ðŸŸ¢ CONNECTOR CONTAINER:**

**Connectors (13):**
- `apps/connector/connectors/aws_secrets_connector.py`
- `apps/connector/connectors/gcp_secrets_connector.py`
- `apps/connector/connectors/infisical_connector.py`
- `apps/connector/connectors/aws_kms_connector.py`
- `apps/connector/connectors/gcp_kms_connector.py`
- `apps/connector/connectors/infisical_keys_connector.py`
- `apps/connector/connectors/aws_iam_connector.py`
- `apps/connector/connectors/gcp_iam_connector.py`
- `apps/connector/connectors/k8s_iam_connector.py`
- `apps/connector/connectors/azure_connector.py`
- `apps/connector/connectors/azure_ad_connector.py`
- `apps/connector/sync/discovery_scheduler.py`
- `apps/connector/sync/discovery_engine.py`

**Tests (24):**
- `tests/api/test_entity_subtypes.py`
- `tests/api/test_secrets.py`
- `tests/api/test_keys.py`
- `tests/api/test_iam.py`
- `tests/api/test_discovery.py`
- `tests/api/test_directory.py`
- `tests/api/test_audit.py`
- `tests/api/test_webhooks.py`
- `tests/api/test_notifications.py`
- `tests/api/test_search.py`
- `tests/api/test_backup.py`
- `tests/connector/test_aws_connector.py`
- `tests/connector/test_gcp_connector.py`
- `tests/connector/test_azure_connector.py`
- `tests/connector/test_aws_iam_connector.py`
- `tests/connector/test_gcp_iam_connector.py`
- `tests/connector/test_k8s_iam_connector.py`
- `tests/connector/test_aws_secrets_connector.py`
- `tests/connector/test_gcp_secrets_connector.py`
- `tests/connector/test_infisical_connector.py`
- `tests/connector/test_ldap_connector.py`
- `tests/connector/test_google_workspace_connector.py`
- `tests/connector/test_azure_ad_connector.py`

**Documentation (10):**
- `docs/ENTITIES.md`
- `docs/SECRETS.md`
- `docs/KEYS.md`
- `docs/CLOUD_DISCOVERY.md`
- `docs/IAM_INTEGRATION.md`
- `docs/DIRECTORY_SYNC.md`
- `docs/WEBHOOKS.md`
- `docs/NOTIFICATIONS.md`
- `docs/BACKUP_RESTORE.md`
- `docs/ARCHITECTURE.md` (updated)

### Updated Files (8)

**ðŸ”µ CORE:**
- `apps/api/models/entity.py` - Add sub-types
- `apps/api/models/pydal_models.py` - New tables
- `apps/api/models/audit.py` - Expand resource types
- `apps/api/database.py` - Add replica support
- `apps/api/main.py` - Register new blueprints
- `README.md` - Update features
- `docs/DATABASE.md` - Add Galera docs
- `docs/RELEASE_NOTES.md` - v1.2.0 notes

**ðŸŸ¢ CONNECTOR:**
- `apps/connector/connectors/aws_connector.py` - Complete discovery
- `apps/connector/connectors/gcp_connector.py` - Complete discovery
- `apps/connector/connectors/ldap_connector.py` - Complete sync
- `apps/connector/connectors/google_workspace_connector.py` - Complete sync

---

## Success Criteria

### From .FUTURE âœ…
- âœ… Entity sub-types for network, compute, storage, datacenter, security
- âœ… Default metadata by entity sub-type
- âœ… User entities migrated to identities
- âœ… Secrets management (AWS, GCP, Infisical) with masking
- âœ… Keys management (AWS KMS, GCP KMS, Infisical)
- âœ… IAM integration (AWS IAM, GCP IAM, K8s RBAC)
- âœ… MariaDB Galera + read replica support
- âœ… AzureAD/Entra ID integration
- âœ… Google Workspace integration (complete)
- âœ… GCP IAM integration
- âœ… AWS IAM integration
- âœ… Kubernetes IAM integration

### Additional Features âœ…
- âœ… Auto-discovery for AWS, GCP, Azure (all major resources)
- âœ… Complete LDAP/AD sync with OU hierarchy
- âœ… Comprehensive audit system with compliance reports
- âœ… Outbound webhooks with signature verification
- âœ… Multi-channel notifications (Email, Slack, Teams)
- âœ… Full-text search with saved searches
- âœ… Backup/restore/import/export functionality

### Quality âœ…
- âœ… 85%+ test coverage
- âœ… Complete documentation for all features
- âœ… Clean separation between ðŸ”µ CORE and ðŸŸ¢ CONNECTOR
- âœ… Production-ready error handling
- âœ… Security best practices (never store secrets/keys locally)

---

## Timeline: 18 weeks

**Week 1-3:** Entity sub-types & model enhancement
**Week 3-6:** Secrets management system
**Week 6-8:** Key management system
**Week 8-10:** IAM integration (AWS, GCP, K8s)
**Week 9-12:** Cloud auto-discovery completion
**Week 11-13:** Directory integration completion
**Week 13-14:** Database enhancement (Galera, replicas)
**Week 14-15:** Audit system enhancement
**Week 15-16:** Webhook & notification system
**Week 16-17:** Advanced search & data management
**Week 17-18:** Testing & documentation

---

## Next Steps

1. **Approve this plan** âœ… DONE
2. **Create feature branch:** `feature/v1.2.0-complete-integration`
3. **Start Phase 1:** Entity sub-types implementation
4. **Implement iteratively:** Complete each phase, test, commit
5. **Document as you go:** Update docs with each feature
6. **Create .TODO file:** Track progress through all phases

---

**This release completes ALL items from .FUTURE and transforms Elder into a comprehensive infrastructure visibility and management platform!**
